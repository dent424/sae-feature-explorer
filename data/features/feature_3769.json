{
  "feature_idx": 3769,
  "stats": {
    "sampling": {
      "method": "sequential_from_start",
      "description": "First N tokens in corpus order (not random)",
      "tokens_scanned": 100000,
      "corpus_coverage": 0.0019
    },
    "total_activations": 28,
    "mean_when_active": 0.06279073442731585,
    "max_activation": 0.2288818359375,
    "std_when_active": 0.059301047256210174,
    "activation_rate": 0.00028
  },
  "top_tokens": {
    "sampling": {
      "method": "sequential_from_start",
      "description": "First N activations in corpus order (not random)",
      "activations_collected": 17612,
      "tokens_scanned": 51702947,
      "corpus_coverage": 1.0
    },
    "top_tokens": [
      {
        "token": " Thank",
        "count": 3629,
        "mean_activation": 0.22635104656876465
      },
      {
        "token": " Best",
        "count": 2718,
        "mean_activation": 0.03489128713488491
      },
      {
        "token": " Thanks",
        "count": 2287,
        "mean_activation": 0.06733319307968613
      },
      {
        "token": " thank",
        "count": 1846,
        "mean_activation": 0.0870449194283036
      },
      {
        "token": " Oh",
        "count": 963,
        "mean_activation": 0.02290345822786864
      },
      {
        "token": "Thank",
        "count": 733,
        "mean_activation": 0.1784403177758356
      },
      {
        "token": " Love",
        "count": 645,
        "mean_activation": 0.020935709162275922
      },
      {
        "token": " Wow",
        "count": 506,
        "mean_activation": 0.026128082878504818
      },
      {
        "token": "thank",
        "count": 335,
        "mean_activation": 0.08695542065065298
      },
      {
        "token": " thanks",
        "count": 327,
        "mean_activation": 0.04597104507119648
      }
    ]
  },
  "top_activations": {
    "sampling": {
      "method": "top_by_activation",
      "description": "Strongest activations within scanned tokens (not full corpus)",
      "top_k_requested": 10,
      "n_found": 10,
      "activations_scanned": 17612,
      "tokens_scanned": 51702947,
      "corpus_coverage": 1.0
    },
    "activations": [
      {
        "context": "...e our night special.** Thank** you",
        "active_token": " Thank",
        "activation": 0.310546875,
        "review_id": "DqYaf3yAxnelk9iYGyPkhA",
        "position": 42
      },
      {
        "context": "...endly and attentive!** Thank** you so much Flory!!...",
        "active_token": " Thank",
        "activation": 0.309326171875,
        "review_id": "BkoM-n7Rm0H9vdOJ5PfKcA",
        "position": 24
      },
      {
        "context": "...rvice was excellent.** Thank** you, Michael for al...",
        "active_token": " Thank",
        "activation": 0.30810546875,
        "review_id": "GVKBnaVJvcl0IDqvNn3o6w",
        "position": 28
      },
      {
        "context": "... her (and the food).** Thank** you Chelsea for mak...",
        "active_token": " Thank",
        "activation": 0.3076171875,
        "review_id": "YTIdw7OYWzo_2IkT1HaHWQ",
        "position": 44
      },
      {
        "context": "...that everyone loved.** Thank** you!",
        "active_token": " Thank",
        "activation": 0.305908203125,
        "review_id": "KJgasuRaQMJSZw0i0yWFEQ",
        "position": 80
      },
      {
        "context": "...ice and tasty eats. ** Thank** you to the staff an...",
        "active_token": " Thank",
        "activation": 0.305908203125,
        "review_id": "tGbis7H5zCcYSO5J9GXXUw",
        "position": 35
      },
      {
        "context": "...d drinks were great.** Thank** you Sharkeez.",
        "active_token": " Thank",
        "activation": 0.305908203125,
        "review_id": "pOmJuh1POCbVCff5sHJ6GA",
        "position": 35
      },
      {
        "context": "...ented and delicious.** Thank** you!",
        "active_token": " Thank",
        "activation": 0.30517578125,
        "review_id": "WlcMfZnacPNI8TY3KWE98A",
        "position": 52
      },
      {
        "context": "...and food were great.** Thank** you Caroline for al...",
        "active_token": " Thank",
        "activation": 0.3046875,
        "review_id": "TDbI2JXxFw07DCnM0jqC-Q",
        "position": 50
      },
      {
        "context": "...for a holiday party.** Thank** you!",
        "active_token": " Thank",
        "activation": 0.3046875,
        "review_id": "C75dhBP-BoMWwzxA6r017A",
        "position": 56
      }
    ]
  },
  "ngram_analysis": {
    "feature_idx": 3769,
    "sampling": {
      "method": "top_by_activation",
      "description": "Top N activations by strength (not random)",
      "n_requested": 500,
      "n_found": 500,
      "tokens_scanned": 51702947,
      "corpus_coverage": 1.0,
      "activation_range": {
        "min": 0.2751,
        "max": 0.3105,
        "mean": 0.2856
      }
    },
    "n_contexts_analyzed": 500,
    "context_window": 5,
    "ngrams": {
      "2grams": [
        {
          "ngram": [
            " Thank",
            " you"
          ],
          "ngram_str": " Thank you",
          "count": 486,
          "percent": 97.2
        },
        {
          "ngram": [
            ".",
            " Thank"
          ],
          "ngram_str": ". Thank",
          "count": 291,
          "percent": 58.2
        },
        {
          "ngram": [
            "!",
            " Thank"
          ],
          "ngram_str": "! Thank",
          "count": 119,
          "percent": 23.8
        },
        {
          "ngram": [
            " you",
            " for"
          ],
          "ngram_str": " you for",
          "count": 96,
          "percent": 19.2
        },
        {
          "ngram": [
            " ",
            " Thank"
          ],
          "ngram_str": "  Thank",
          "count": 68,
          "percent": 13.6
        },
        {
          "ngram": [
            " you",
            "!"
          ],
          "ngram_str": " you!",
          "count": 65,
          "percent": 13.0
        },
        {
          "ngram": [
            ".",
            " "
          ],
          "ngram_str": ". ",
          "count": 49,
          "percent": 9.8
        },
        {
          "ngram": [
            " you",
            " so"
          ],
          "ngram_str": " you so",
          "count": 44,
          "percent": 8.8
        },
        {
          "ngram": [
            " so",
            " much"
          ],
          "ngram_str": " so much",
          "count": 43,
          "percent": 8.6
        },
        {
          "ngram": [
            " for",
            " a"
          ],
          "ngram_str": " for a",
          "count": 33,
          "percent": 6.6
        },
        {
          "ngram": [
            " a",
            " great"
          ],
          "ngram_str": " a great",
          "count": 27,
          "percent": 5.4
        },
        {
          "ngram": [
            " for",
            " the"
          ],
          "ngram_str": " for the",
          "count": 27,
          "percent": 5.4
        },
        {
          "ngram": [
            " you",
            ","
          ],
          "ngram_str": " you,",
          "count": 23,
          "percent": 4.6
        },
        {
          "ngram": [
            "!",
            " "
          ],
          "ngram_str": "! ",
          "count": 23,
          "percent": 4.6
        },
        {
          "ngram": [
            " you",
            " to"
          ],
          "ngram_str": " you to",
          "count": 21,
          "percent": 4.2
        }
      ],
      "3grams": [
        {
          "ngram": [
            ".",
            " Thank",
            " you"
          ],
          "ngram_str": ". Thank you",
          "count": 282,
          "percent": 56.4
        },
        {
          "ngram": [
            "!",
            " Thank",
            " you"
          ],
          "ngram_str": "! Thank you",
          "count": 118,
          "percent": 23.6
        },
        {
          "ngram": [
            " Thank",
            " you",
            " for"
          ],
          "ngram_str": " Thank you for",
          "count": 96,
          "percent": 19.2
        },
        {
          "ngram": [
            " ",
            " Thank",
            " you"
          ],
          "ngram_str": "  Thank you",
          "count": 67,
          "percent": 13.4
        },
        {
          "ngram": [
            " Thank",
            " you",
            "!"
          ],
          "ngram_str": " Thank you!",
          "count": 65,
          "percent": 13.0
        },
        {
          "ngram": [
            " Thank",
            " you",
            " so"
          ],
          "ngram_str": " Thank you so",
          "count": 43,
          "percent": 8.6
        },
        {
          "ngram": [
            ".",
            " ",
            " Thank"
          ],
          "ngram_str": ".  Thank",
          "count": 43,
          "percent": 8.6
        },
        {
          "ngram": [
            " you",
            " so",
            " much"
          ],
          "ngram_str": " you so much",
          "count": 39,
          "percent": 7.8
        },
        {
          "ngram": [
            " Thank",
            " you",
            ","
          ],
          "ngram_str": " Thank you,",
          "count": 23,
          "percent": 4.6
        },
        {
          "ngram": [
            " you",
            " for",
            " a"
          ],
          "ngram_str": " you for a",
          "count": 23,
          "percent": 4.6
        },
        {
          "ngram": [
            " you",
            " for",
            " the"
          ],
          "ngram_str": " you for the",
          "count": 23,
          "percent": 4.6
        },
        {
          "ngram": [
            " Thank",
            " you",
            " to"
          ],
          "ngram_str": " Thank you to",
          "count": 21,
          "percent": 4.2
        },
        {
          "ngram": [
            "!",
            " ",
            " Thank"
          ],
          "ngram_str": "!  Thank",
          "count": 18,
          "percent": 3.6
        },
        {
          "ngram": [
            " so",
            " much",
            " for"
          ],
          "ngram_str": " so much for",
          "count": 15,
          "percent": 3.0
        },
        {
          "ngram": [
            " for",
            " a",
            " great"
          ],
          "ngram_str": " for a great",
          "count": 13,
          "percent": 2.6
        }
      ],
      "4grams": [
        {
          "ngram": [
            ".",
            " Thank",
            " you",
            " for"
          ],
          "ngram_str": ". Thank you for",
          "count": 56,
          "percent": 11.2
        },
        {
          "ngram": [
            ".",
            " ",
            " Thank",
            " you"
          ],
          "ngram_str": ".  Thank you",
          "count": 42,
          "percent": 8.4
        },
        {
          "ngram": [
            ".",
            " Thank",
            " you",
            "!"
          ],
          "ngram_str": ". Thank you!",
          "count": 41,
          "percent": 8.2
        },
        {
          "ngram": [
            " Thank",
            " you",
            " so",
            " much"
          ],
          "ngram_str": " Thank you so much",
          "count": 38,
          "percent": 7.6
        },
        {
          "ngram": [
            " Thank",
            " you",
            " for",
            " a"
          ],
          "ngram_str": " Thank you for a",
          "count": 23,
          "percent": 4.6
        },
        {
          "ngram": [
            " Thank",
            " you",
            " for",
            " the"
          ],
          "ngram_str": " Thank you for the",
          "count": 23,
          "percent": 4.6
        },
        {
          "ngram": [
            "!",
            " Thank",
            " you",
            " for"
          ],
          "ngram_str": "! Thank you for",
          "count": 22,
          "percent": 4.4
        },
        {
          "ngram": [
            "!",
            " Thank",
            " you",
            " so"
          ],
          "ngram_str": "! Thank you so",
          "count": 18,
          "percent": 3.6
        },
        {
          "ngram": [
            "!",
            " ",
            " Thank",
            " you"
          ],
          "ngram_str": "!  Thank you",
          "count": 18,
          "percent": 3.6
        },
        {
          "ngram": [
            ".",
            " Thank",
            " you",
            " so"
          ],
          "ngram_str": ". Thank you so",
          "count": 17,
          "percent": 3.4
        },
        {
          "ngram": [
            "!",
            " Thank",
            " you",
            "!"
          ],
          "ngram_str": "! Thank you!",
          "count": 15,
          "percent": 3.0
        },
        {
          "ngram": [
            ".",
            " Thank",
            " you",
            ","
          ],
          "ngram_str": ". Thank you,",
          "count": 14,
          "percent": 2.8
        },
        {
          "ngram": [
            ".",
            " Thank",
            " you",
            " to"
          ],
          "ngram_str": ". Thank you to",
          "count": 13,
          "percent": 2.6
        },
        {
          "ngram": [
            " you",
            " so",
            " much",
            " for"
          ],
          "ngram_str": " you so much for",
          "count": 13,
          "percent": 2.6
        },
        {
          "ngram": [
            " great",
            ".",
            " Thank",
            " you"
          ],
          "ngram_str": " great. Thank you",
          "count": 12,
          "percent": 2.4
        }
      ]
    }
  },
  "coactivation": {
    "sampling": {
      "method": "sequential_from_start",
      "description": "First N activations in corpus order",
      "activations_sampled": 10000,
      "tokens_scanned": 29600000,
      "corpus_coverage": 0.5725
    },
    "coactivated_features": [
      {
        "feature_idx": 19889,
        "count": 8079,
        "percent": 80.79
      },
      {
        "feature_idx": 19167,
        "count": 6798,
        "percent": 67.98
      },
      {
        "feature_idx": 20204,
        "count": 6518,
        "percent": 65.18
      },
      {
        "feature_idx": 18704,
        "count": 6349,
        "percent": 63.49
      },
      {
        "feature_idx": 13336,
        "count": 5682,
        "percent": 56.82
      },
      {
        "feature_idx": 16641,
        "count": 5607,
        "percent": 56.07
      },
      {
        "feature_idx": 22650,
        "count": 5597,
        "percent": 55.97
      },
      {
        "feature_idx": 506,
        "count": 5517,
        "percent": 55.17
      },
      {
        "feature_idx": 8912,
        "count": 5266,
        "percent": 52.66
      },
      {
        "feature_idx": 12038,
        "count": 5204,
        "percent": 52.04
      },
      {
        "feature_idx": 14766,
        "count": 4575,
        "percent": 45.75
      },
      {
        "feature_idx": 886,
        "count": 4336,
        "percent": 43.36
      },
      {
        "feature_idx": 8566,
        "count": 4229,
        "percent": 42.29
      },
      {
        "feature_idx": 5196,
        "count": 4201,
        "percent": 42.01
      },
      {
        "feature_idx": 6329,
        "count": 3998,
        "percent": 39.98
      },
      {
        "feature_idx": 12563,
        "count": 3946,
        "percent": 39.46
      },
      {
        "feature_idx": 15198,
        "count": 3835,
        "percent": 38.35
      },
      {
        "feature_idx": 15265,
        "count": 3412,
        "percent": 34.12
      },
      {
        "feature_idx": 22894,
        "count": 3272,
        "percent": 32.72
      },
      {
        "feature_idx": 17175,
        "count": 3154,
        "percent": 31.54
      }
    ]
  },
  "position_distribution": {
    "sampling": {
      "method": "sequential_from_start",
      "description": "First N activations in corpus order",
      "activations_sampled": 10000,
      "tokens_scanned": 29600000,
      "corpus_coverage": 0.5725
    },
    "bins": [
      {
        "range": "0-20%",
        "label": "early",
        "count": 820,
        "percent": 8.2
      },
      {
        "range": "20-40%",
        "label": "early-mid",
        "count": 1078,
        "percent": 10.78
      },
      {
        "range": "40-60%",
        "label": "middle",
        "count": 1288,
        "percent": 12.88
      },
      {
        "range": "60-80%",
        "label": "late-mid",
        "count": 2046,
        "percent": 20.46
      },
      {
        "range": "80-100%",
        "label": "late",
        "count": 4768,
        "percent": 47.68
      }
    ],
    "mean_position": 0.6879,
    "std_position": 0.2744
  },
  "activation_distribution": {
    "sampling": {
      "method": "sequential_from_start",
      "description": "First N tokens in corpus order",
      "tokens_scanned": 100000,
      "n_activations": 28,
      "corpus_coverage": 0.0019
    },
    "percentiles": {
      "p10": 0.017,
      "p25": 0.0246,
      "p50": 0.0393,
      "p75": 0.0728,
      "p90": 0.1332,
      "p95": 0.2135,
      "p99": 0.2255
    },
    "skewness": 1.805,
    "kurtosis": 2.2104,
    "min": 0.015,
    "max": 0.2289,
    "mean": 0.0628,
    "std": 0.0593
  },
  "top_token_contexts": {
    "sampling": {
      "method": "sequential_from_start",
      "description": "First N tokens in corpus order, top activations per token",
      "tokens_scanned": 100000,
      "corpus_coverage": 0.0019,
      "activations_found": 28,
      "unique_tokens_found": 15
    },
    "tokens": [
      {
        "token": " Thanks",
        "count": 7,
        "mean_activation": 0.0592
      },
      {
        "token": " Best",
        "count": 5,
        "mean_activation": 0.0403
      },
      {
        "token": " Thank",
        "count": 3,
        "mean_activation": 0.2178
      },
      {
        "token": " thank",
        "count": 2,
        "mean_activation": 0.0694
      },
      {
        "token": " Wish",
        "count": 1,
        "mean_activation": 0.0286
      },
      {
        "token": "oint",
        "count": 1,
        "mean_activation": 0.0478
      },
      {
        "token": " Great",
        "count": 1,
        "mean_activation": 0.0204
      },
      {
        "token": " Oh",
        "count": 1,
        "mean_activation": 0.0155
      },
      {
        "token": "Oh",
        "count": 1,
        "mean_activation": 0.015
      },
      {
        "token": "Thanks",
        "count": 1,
        "mean_activation": 0.0362
      }
    ]
  }
}