{
  "feature_idx": 7302,
  "stats": {
    "sampling": {
      "method": "sequential_from_start",
      "description": "First N tokens in corpus order (not random)",
      "tokens_scanned": 100000,
      "corpus_coverage": 0.0019
    },
    "total_activations": 37,
    "mean_when_active": 0.1131641284839527,
    "max_activation": 0.292724609375,
    "std_when_active": 0.0630679080865357,
    "activation_rate": 0.00037
  },
  "top_tokens": {
    "sampling": {
      "method": "sequential_from_start",
      "description": "First N activations in corpus order (not random)",
      "activations_collected": 16235,
      "tokens_scanned": 51702947,
      "corpus_coverage": 1.0
    },
    "top_tokens": [
      {
        "token": " due",
        "count": 5629,
        "mean_activation": 0.15417578868828694
      },
      {
        "token": " Thanks",
        "count": 2599,
        "mean_activation": 0.09571810197995323
      },
      {
        "token": " thanks",
        "count": 1784,
        "mean_activation": 0.15361098216788116
      },
      {
        "token": " thank",
        "count": 720,
        "mean_activation": 0.05251125759548611
      },
      {
        "token": "Thanks",
        "count": 590,
        "mean_activation": 0.10966326180150954
      },
      {
        "token": " Thank",
        "count": 502,
        "mean_activation": 0.024466647569876744
      },
      {
        "token": " IM",
        "count": 321,
        "mean_activation": 0.038638533832870914
      },
      {
        "token": " Due",
        "count": 246,
        "mean_activation": 0.12131717340732978
      },
      {
        "token": "thanks",
        "count": 245,
        "mean_activation": 0.16290295659279336
      },
      {
        "token": " med",
        "count": 239,
        "mean_activation": 0.037502081324365846
      }
    ]
  },
  "top_activations": {
    "sampling": {
      "method": "top_by_activation",
      "description": "Strongest activations within scanned tokens (not full corpus)",
      "top_k_requested": 10,
      "n_found": 10,
      "activations_scanned": 16235,
      "tokens_scanned": 51702947,
      "corpus_coverage": 1.0
    },
    "activations": [
      {
        "context": "...rite for many years** thanks** to their prepared f...",
        "active_token": " thanks",
        "activation": 0.335693359375,
        "review_id": "tFDbFv_Z3VLwD6klhNPNwQ",
        "position": 118
      },
      {
        "context": "...st about everywhere** thanks** to Mr Mitchells ten...",
        "active_token": " thanks",
        "activation": 0.3349609375,
        "review_id": "jAjkY-WUXoIcj4smH6nJ-Q",
        "position": 118
      },
      {
        "context": "... is cool and breezy** thanks** to dozens of quiet ...",
        "active_token": " thanks",
        "activation": 0.333984375,
        "review_id": "oNTCAyRUi1_AZiEBP1Gvdg",
        "position": 86
      },
      {
        "context": "...er meaty and savory** thanks** to chorizo and chee...",
        "active_token": " thanks",
        "activation": 0.329833984375,
        "review_id": "tgPzROEyxGHoWEL-YbAS9Q",
        "position": 160
      },
      {
        "context": "...dibly into drinking** thanks** to my featherweight...",
        "active_token": " thanks",
        "activation": 0.3291015625,
        "review_id": "OLYEY3d-HiLK4RfsllWvQw",
        "position": 21
      },
      {
        "context": "... our regular palate** thanks** to the wide spread ...",
        "active_token": " thanks",
        "activation": 0.3291015625,
        "review_id": "dXkwX1ciWgBk2jyIivXXCw",
        "position": 167
      },
      {
        "context": "...bience is memorable** thanks** to the hand-carved ...",
        "active_token": " thanks",
        "activation": 0.323486328125,
        "review_id": "poPyycgsBnDoWQG3SRmpUQ",
        "position": 29
      },
      {
        "context": "...the Westshore noise** thanks** to the landscaping....",
        "active_token": " thanks",
        "activation": 0.3232421875,
        "review_id": "p95TJYWW9PyeOd5JNBV6kw",
        "position": 165
      },
      {
        "context": "...ns, rice and cheese** thanks** to Taco Bell and On...",
        "active_token": " thanks",
        "activation": 0.322021484375,
        "review_id": "LDnemSk-i9ZZTA0aJ28plg",
        "position": 125
      },
      {
        "context": "...os was a great find** thanks** to the recommendati...",
        "active_token": " thanks",
        "activation": 0.320068359375,
        "review_id": "YZdr0SgKliqb6qbYfyFzuA",
        "position": 40
      }
    ]
  },
  "ngram_analysis": {
    "feature_idx": 7302,
    "sampling": {
      "method": "top_by_activation",
      "description": "Top N activations by strength (not random)",
      "n_requested": 500,
      "n_found": 500,
      "tokens_scanned": 51702947,
      "corpus_coverage": 1.0,
      "activation_range": {
        "min": 0.2286,
        "max": 0.3357,
        "mean": 0.261
      }
    },
    "n_contexts_analyzed": 500,
    "context_window": 5,
    "ngrams": {
      "2grams": [
        {
          "ngram": [
            " thanks",
            " to"
          ],
          "ngram_str": " thanks to",
          "count": 303,
          "percent": 60.6
        },
        {
          "ngram": [
            " to",
            " the"
          ],
          "ngram_str": " to the",
          "count": 142,
          "percent": 28.4
        },
        {
          "ngram": [
            " due",
            " to"
          ],
          "ngram_str": " due to",
          "count": 96,
          "percent": 19.2
        },
        {
          "ngram": [
            ",",
            " thanks"
          ],
          "ngram_str": ", thanks",
          "count": 87,
          "percent": 17.4
        },
        {
          "ngram": [
            " to",
            " a"
          ],
          "ngram_str": " to a",
          "count": 21,
          "percent": 4.2
        },
        {
          "ngram": [
            " service",
            " was"
          ],
          "ngram_str": " service was",
          "count": 20,
          "percent": 4.0
        },
        {
          "ngram": [
            " thanks",
            " for"
          ],
          "ngram_str": " thanks for",
          "count": 20,
          "percent": 4.0
        },
        {
          "ngram": [
            " to",
            " their"
          ],
          "ngram_str": " to their",
          "count": 19,
          "percent": 3.8
        },
        {
          "ngram": [
            " to",
            " my"
          ],
          "ngram_str": " to my",
          "count": 18,
          "percent": 3.6
        },
        {
          "ngram": [
            " to",
            " Yelp"
          ],
          "ngram_str": " to Yelp",
          "count": 16,
          "percent": 3.2
        },
        {
          "ngram": [
            "\u00c4",
            "\u012c"
          ],
          "ngram_str": "\u00c4\u012c",
          "count": 15,
          "percent": 3.0
        },
        {
          "ngram": [
            " to",
            " our"
          ],
          "ngram_str": " to our",
          "count": 15,
          "percent": 3.0
        },
        {
          "ngram": [
            ".",
            " "
          ],
          "ngram_str": ". ",
          "count": 14,
          "percent": 2.8
        },
        {
          "ngram": [
            " thanks",
            "."
          ],
          "ngram_str": " thanks.",
          "count": 13,
          "percent": 2.6
        },
        {
          "ngram": [
            " slow",
            " due"
          ],
          "ngram_str": " slow due",
          "count": 13,
          "percent": 2.6
        }
      ],
      "3grams": [
        {
          "ngram": [
            " thanks",
            " to",
            " the"
          ],
          "ngram_str": " thanks to the",
          "count": 93,
          "percent": 18.6
        },
        {
          "ngram": [
            ",",
            " thanks",
            " to"
          ],
          "ngram_str": ", thanks to",
          "count": 52,
          "percent": 10.4
        },
        {
          "ngram": [
            " due",
            " to",
            " the"
          ],
          "ngram_str": " due to the",
          "count": 43,
          "percent": 8.6
        },
        {
          "ngram": [
            " thanks",
            " to",
            " my"
          ],
          "ngram_str": " thanks to my",
          "count": 17,
          "percent": 3.4
        },
        {
          "ngram": [
            " thanks",
            " to",
            " Yelp"
          ],
          "ngram_str": " thanks to Yelp",
          "count": 16,
          "percent": 3.2
        },
        {
          "ngram": [
            " thanks",
            " to",
            " a"
          ],
          "ngram_str": " thanks to a",
          "count": 15,
          "percent": 3.0
        },
        {
          "ngram": [
            " thanks",
            " to",
            " their"
          ],
          "ngram_str": " thanks to their",
          "count": 14,
          "percent": 2.8
        },
        {
          "ngram": [
            " thanks",
            " to",
            " our"
          ],
          "ngram_str": " thanks to our",
          "count": 13,
          "percent": 2.6
        },
        {
          "ngram": [
            " slow",
            " due",
            " to"
          ],
          "ngram_str": " slow due to",
          "count": 13,
          "percent": 2.6
        },
        {
          "ngram": [
            ",",
            " thanks",
            " for"
          ],
          "ngram_str": ", thanks for",
          "count": 12,
          "percent": 2.4
        },
        {
          "ngram": [
            " to",
            " Yelp",
            "."
          ],
          "ngram_str": " to Yelp.",
          "count": 10,
          "percent": 2.0
        },
        {
          "ngram": [
            " place",
            " thanks",
            " to"
          ],
          "ngram_str": " place thanks to",
          "count": 10,
          "percent": 2.0
        },
        {
          "ngram": [
            " experience",
            " thanks",
            " to"
          ],
          "ngram_str": " experience thanks to",
          "count": 7,
          "percent": 1.4
        },
        {
          "ngram": [
            " thanks",
            " for",
            " the"
          ],
          "ngram_str": " thanks for the",
          "count": 7,
          "percent": 1.4
        },
        {
          "ngram": [
            " thanks",
            " to",
            " this"
          ],
          "ngram_str": " thanks to this",
          "count": 7,
          "percent": 1.4
        }
      ],
      "4grams": [
        {
          "ngram": [
            ",",
            " thanks",
            " to",
            " the"
          ],
          "ngram_str": ", thanks to the",
          "count": 17,
          "percent": 3.4
        },
        {
          "ngram": [
            " thanks",
            " to",
            " Yelp",
            "."
          ],
          "ngram_str": " thanks to Yelp.",
          "count": 10,
          "percent": 2.0
        },
        {
          "ngram": [
            " this",
            " place",
            " thanks",
            " to"
          ],
          "ngram_str": " this place thanks to",
          "count": 7,
          "percent": 1.4
        },
        {
          "ngram": [
            " place",
            " thanks",
            " to",
            " Yelp"
          ],
          "ngram_str": " place thanks to Yelp",
          "count": 6,
          "percent": 1.2
        },
        {
          "ngram": [
            "\u00c4",
            "\u012c",
            "\u00c4",
            "\u012c"
          ],
          "ngram_str": "\u00c4\u012c\u00c4\u012c",
          "count": 6,
          "percent": 1.2
        },
        {
          "ngram": [
            " in",
            "ed",
            "ible",
            " due"
          ],
          "ngram_str": " inedible due",
          "count": 6,
          "percent": 1.2
        },
        {
          "ngram": [
            "ed",
            "ible",
            " due",
            " to"
          ],
          "ngram_str": "edible due to",
          "count": 6,
          "percent": 1.2
        },
        {
          "ngram": [
            " time",
            " thanks",
            " to",
            " the"
          ],
          "ngram_str": " time thanks to the",
          "count": 5,
          "percent": 1.0
        },
        {
          "ngram": [
            " thanks",
            " to",
            " y",
            "el"
          ],
          "ngram_str": " thanks to yel",
          "count": 5,
          "percent": 1.0
        },
        {
          "ngram": [
            " thanks",
            " to",
            " our",
            " server"
          ],
          "ngram_str": " thanks to our server",
          "count": 5,
          "percent": 1.0
        },
        {
          "ngram": [
            " was",
            " slow",
            " due",
            " to"
          ],
          "ngram_str": " was slow due to",
          "count": 5,
          "percent": 1.0
        },
        {
          "ngram": [
            " a",
            " great",
            " find",
            " thanks"
          ],
          "ngram_str": " a great find thanks",
          "count": 4,
          "percent": 0.8
        },
        {
          "ngram": [
            " great",
            " find",
            " thanks",
            " to"
          ],
          "ngram_str": " great find thanks to",
          "count": 4,
          "percent": 0.8
        },
        {
          "ngram": [
            " to",
            " y",
            "el",
            "p"
          ],
          "ngram_str": " to yelp",
          "count": 4,
          "percent": 0.8
        },
        {
          "ngram": [
            ",",
            " thanks",
            " for",
            " the"
          ],
          "ngram_str": ", thanks for the",
          "count": 4,
          "percent": 0.8
        }
      ]
    }
  },
  "coactivation": {
    "sampling": {
      "method": "sequential_from_start",
      "description": "First N activations in corpus order",
      "activations_sampled": 10000,
      "tokens_scanned": 32100000,
      "corpus_coverage": 0.6209
    },
    "coactivated_features": [
      {
        "feature_idx": 19167,
        "count": 4965,
        "percent": 49.65
      },
      {
        "feature_idx": 22650,
        "count": 4652,
        "percent": 46.52
      },
      {
        "feature_idx": 779,
        "count": 4379,
        "percent": 43.79
      },
      {
        "feature_idx": 13336,
        "count": 4367,
        "percent": 43.67
      },
      {
        "feature_idx": 16641,
        "count": 4280,
        "percent": 42.8
      },
      {
        "feature_idx": 506,
        "count": 4224,
        "percent": 42.24
      },
      {
        "feature_idx": 8912,
        "count": 4165,
        "percent": 41.65
      },
      {
        "feature_idx": 7944,
        "count": 3813,
        "percent": 38.13
      },
      {
        "feature_idx": 17175,
        "count": 3793,
        "percent": 37.93
      },
      {
        "feature_idx": 5092,
        "count": 3792,
        "percent": 37.92
      },
      {
        "feature_idx": 15420,
        "count": 3769,
        "percent": 37.69
      },
      {
        "feature_idx": 6056,
        "count": 3766,
        "percent": 37.66
      },
      {
        "feature_idx": 5196,
        "count": 3756,
        "percent": 37.56
      },
      {
        "feature_idx": 16234,
        "count": 3731,
        "percent": 37.31
      },
      {
        "feature_idx": 11763,
        "count": 3692,
        "percent": 36.92
      },
      {
        "feature_idx": 20204,
        "count": 3611,
        "percent": 36.11
      },
      {
        "feature_idx": 1386,
        "count": 3588,
        "percent": 35.88
      },
      {
        "feature_idx": 8566,
        "count": 3551,
        "percent": 35.51
      },
      {
        "feature_idx": 928,
        "count": 3411,
        "percent": 34.11
      },
      {
        "feature_idx": 3913,
        "count": 3355,
        "percent": 33.55
      }
    ]
  },
  "position_distribution": {
    "sampling": {
      "method": "sequential_from_start",
      "description": "First N activations in corpus order",
      "activations_sampled": 10000,
      "tokens_scanned": 32100000,
      "corpus_coverage": 0.6209
    },
    "bins": [
      {
        "range": "0-20%",
        "label": "early",
        "count": 1635,
        "percent": 16.35
      },
      {
        "range": "20-40%",
        "label": "early-mid",
        "count": 1544,
        "percent": 15.44
      },
      {
        "range": "40-60%",
        "label": "middle",
        "count": 1455,
        "percent": 14.55
      },
      {
        "range": "60-80%",
        "label": "late-mid",
        "count": 1759,
        "percent": 17.59
      },
      {
        "range": "80-100%",
        "label": "late",
        "count": 3607,
        "percent": 36.07
      }
    ],
    "mean_position": 0.5906,
    "std_position": 0.3119
  },
  "activation_distribution": {
    "sampling": {
      "method": "sequential_from_start",
      "description": "First N tokens in corpus order",
      "tokens_scanned": 100000,
      "n_activations": 37,
      "corpus_coverage": 0.0019
    },
    "percentiles": {
      "p10": 0.03,
      "p25": 0.0537,
      "p50": 0.1062,
      "p75": 0.1473,
      "p90": 0.1964,
      "p95": 0.2054,
      "p99": 0.2644
    },
    "skewness": 0.5578,
    "kurtosis": 0.0092,
    "min": 0.0245,
    "max": 0.2927,
    "mean": 0.1132,
    "std": 0.0631
  },
  "top_token_contexts": {
    "sampling": {
      "method": "sequential_from_start",
      "description": "First N tokens in corpus order, top activations per token",
      "tokens_scanned": 100000,
      "corpus_coverage": 0.0019,
      "activations_found": 37,
      "unique_tokens_found": 13
    },
    "tokens": [
      {
        "token": " due",
        "count": 16,
        "mean_activation": 0.1561
      },
      {
        "token": " Thanks",
        "count": 7,
        "mean_activation": 0.1026
      },
      {
        "token": " Thank",
        "count": 2,
        "mean_activation": 0.0374
      },
      {
        "token": "Thanks",
        "count": 2,
        "mean_activation": 0.0966
      },
      {
        "token": " thanks",
        "count": 2,
        "mean_activation": 0.1721
      },
      {
        "token": " med",
        "count": 1,
        "mean_activation": 0.0413
      },
      {
        "token": " close",
        "count": 1,
        "mean_activation": 0.0313
      },
      {
        "token": " along",
        "count": 1,
        "mean_activation": 0.0245
      },
      {
        "token": " haha",
        "count": 1,
        "mean_activation": 0.0253
      },
      {
        "token": " Due",
        "count": 1,
        "mean_activation": 0.1137
      }
    ]
  }
}